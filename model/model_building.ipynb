{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918d24eb",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction Model Development\n",
    "This notebook builds a machine learning model to predict Titanic passenger survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b100de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeab7dc",
   "metadata": {},
   "source": [
    "## Step 1: Load the Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb85dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = '../../../Titanic2/Titanic-Dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "print(df.head())\n",
    "print(f'\\nDataset info:')\n",
    "print(df.info())\n",
    "print(f'\\nMissing values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50b6b1",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "Selected features: Pclass, Sex, Age, SibSp, Fare (5 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the required columns\n",
    "required_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Survived']\n",
    "df_clean = df[required_features].copy()\n",
    "\n",
    "print('Selected features:')\n",
    "print(df_clean.columns.tolist())\n",
    "print(f'\\nShape after feature selection: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print('Missing values before handling:')\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Drop rows with missing Survived values (target variable)\n",
    "df_clean = df_clean.dropna(subset=['Survived'])\n",
    "\n",
    "# Fill missing Age values with median\n",
    "df_clean['Age'].fillna(df_clean['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Fare values with median\n",
    "df_clean['Fare'].fillna(df_clean['Fare'].median(), inplace=True)\n",
    "\n",
    "print('\\nMissing values after handling:')\n",
    "print(df_clean.isnull().sum())\n",
    "print(f'\\nDataset shape after preprocessing: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "# Sex: Male=1, Female=0\n",
    "df_clean['Sex'] = (df_clean['Sex'] == 'male').astype(int)\n",
    "\n",
    "print('Encoded Sex feature:')\n",
    "print(df_clean['Sex'].value_counts())\n",
    "print('\\nFirst few rows after encoding:')\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_clean[['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']]\n",
    "y = df_clean['Survived']\n",
    "\n",
    "# Save feature names for later use in the web app\n",
    "selected_features = X.columns.tolist()\n",
    "print(f'Input features: {selected_features}')\n",
    "print(f'Target variable: Survived')\n",
    "print(f'\\nFeature matrix shape: {X.shape}')\n",
    "print(f'Target vector shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc970321",
   "metadata": {},
   "source": [
    "## Step 3: Train-Test Split (BEFORE Scaling - Prevent Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Split BEFORE scaling to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'\\nTraining set survival distribution:')\n",
    "print(y_train.value_counts())\n",
    "print(f'\\nTest set survival distribution:')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4805d2",
   "metadata": {},
   "source": [
    "## Step 4: Feature Scaling (FIT ONLY ON TRAINING DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FIT scaler ONLY on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply scaler to test data (using transform, NOT fit_transform)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Scaler fitted on training data only')\n",
    "print(f'Training data scaled shape: {X_train_scaled.shape}')\n",
    "print(f'Test data scaled shape: {X_test_scaled.shape}')\n",
    "print(f'\\nScaler mean: {scaler.mean_}')\n",
    "print(f'Scaler scale: {scaler.scale_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2bae4",
   "metadata": {},
   "source": [
    "## Step 5: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e52b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Random Forest Classifier trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2c2f9",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177712cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CLASSIFICATION REPORT (Test Set)')\n",
    "print('='*60)\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                          target_names=['Did Not Survive', 'Survived']))\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('CONFUSION MATRIX (Test Set)')\n",
    "print('='*60)\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print('Feature Importance:')\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5272b",
   "metadata": {},
   "source": [
    "## Step 7: Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf99a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "os.makedirs('.', exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = 'titanic_survival_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f'Model saved to {model_path}')\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = 'titanic_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f'Scaler saved to {scaler_path}')\n",
    "\n",
    "# Save feature names\n",
    "features_path = 'selected_features.pkl'\n",
    "joblib.dump(selected_features, features_path)\n",
    "print(f'Selected features saved to {features_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836f5eb",
   "metadata": {},
   "source": [
    "## Step 8: Verify Model Can Be Reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the saved model\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_features = joblib.load(features_path)\n",
    "\n",
    "print('All artifacts reloaded successfully!')\n",
    "print(f'\\nLoaded features: {loaded_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with reloaded model\n",
    "test_sample = X_test.iloc[0:1]\n",
    "test_sample_scaled = loaded_scaler.transform(test_sample)\n",
    "\n",
    "# Predict class label\n",
    "predicted_class = loaded_model.predict(test_sample_scaled)[0]\n",
    "\n",
    "# Get prediction probabilities\n",
    "probabilities = loaded_model.predict_proba(test_sample_scaled)[0]\n",
    "confidence = float(np.max(probabilities)) * 100\n",
    "\n",
    "print('Test prediction with reloaded model:')\n",
    "print(f'Sample: {test_sample.values}')\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Probabilities: {probabilities}')\n",
    "print(f'Confidence: {confidence:.2f}%')\n",
    "print(f'\\nActual value: {y_test.iloc[0]}')\n",
    "print(f'Prediction correct: {predicted_class == y_test.iloc[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4049f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Algorithm**: Random Forest Classifier\n",
    "- **Features Used**: Pclass, Sex, Age, SibSp, Fare (5 features)\n",
    "- **Target Variable**: Survived (0 = Did Not Survive, 1 = Survived)\n",
    "- **Test Accuracy**: {:.2f}%\n",
    "- **Model Persistence**: Joblib\n",
    "- **Data Leakage Prevention**: Scaling performed ONLY on training data\n",
    "- **Feature Validation**: Feature names saved for app.py validation\n",
    "\"\"\".format(test_accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e02aca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
